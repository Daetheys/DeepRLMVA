{
    "env":"Reacher-v2",
    "trainer":{
	"nb_fit_per_epoch":10000,
	"train_batch_size":64,
	"training_rollout_length":2048,
	"testing_rollout_length":1000,
	"policy_optimizer":"adam",
	"policy_learning_rate": 5e-5,
	"value_optimizer":"adam",
	"value_learning_rate": 5e-5,
	"kl_coeff":0.0,
	"entropy_coeff":0.0,
	"clip_eps":0.2,
	"clip_grad":10,
	"reward_scale":10,
	"gamma":0.99,
	"decay":0.97,
	"mask_done":false,
	"gae_std":true,
	"replay_buffer_size":2048},
    "seed":0,
    "nb_env":1,
    "nb_steps":1000000
}
